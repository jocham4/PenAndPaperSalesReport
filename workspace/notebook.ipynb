{"cells":[{"source":"# Data Analyst Professional Practical Exam Submission\n\n**You can use any tool that you want to do your analysis and create visualizations. Use this template to write up your summary for submission.**\n\nYou can use any markdown formatting you wish. If you are not familiar with Markdown, read the [Markdown Guide](https://s3.amazonaws.com/talent-assets.datacamp.com/Markdown+Guide.pdf) before you start.\n","metadata":{},"id":"a3d4387f-fa24-4a80-906b-4cca195b6736","cell_type":"markdown"},{"source":"## 📝 Task List\n\nYour written report should include written text summaries and graphics of the following:\n- Data validation:   \n  - Describe validation and cleaning steps for every column in the data \n- Exploratory Analysis:  \n  - Include two different graphics showing single variables only to demonstrate the characteristics of data  \n  - Include at least one graphic showing two or more variables to represent the relationship between features\n  - Describe your findings\n- Definition of a metric for the business to monitor  \n  - How should the business use the metric to monitor the business problem\n  - Can you estimate initial value(s) for the metric based on the current data\n- Final summary including recommendations that the business should undertake\n\n*Start writing report here..*","metadata":{},"id":"562d9d77-2e1e-4523-a28e-1e3b388f930c","cell_type":"markdown"},{"source":"###\n","metadata":{},"cell_type":"markdown","id":"eaf3b5e2-13ec-432d-a593-b69e68c67353"},{"source":"# Sales Report for Pens and Printer\n### By Jonah Chambers","metadata":{},"cell_type":"markdown","id":"74d3a424-e2bf-4bc6-93e2-01f5e73d8603"},{"source":"## Data Validation:\nData validation was performed for each column in the product sales dataset. The first step was to check for NaN/null values which was done for the entire dataset, and only found in the revenue column. A summary of the validation effort for each variable is as follows:\n\n- Week:\n\t- Looking for any values outside of the range of weeks provided (0-6). Used `pd['week'].value_counts` to verify, everything looked appropriate.\n- Sales Method:\n\t- Looking for any values outside of standard values (Email, Call, Email + Call). Used `pd['sales_method'].value_counts` to verify, found several non-conforming values. In order to clean the following code was used:\n    \t`sales.replace('em + call','Email + Call', inplace = True)\n\t\tsales.replace('email','Email', inplace = True)`\n    \n- Customer Id:\n\t- Want to ensure that each value is unique, since we expect one order per customer, and one entry per customer. The following code was used to ensure that their were no duplicates:\n    ` sales.shape == sales.drop_duplicates(subset= 'customer_id').shape`\n- Number of products sold (nb_sold):\n\t- In this case we are looking for any outliers that wouldn't be appropriate. `pd['nb_sold'].value_counts` was used and no anomolus values were found.\n    \n- Revenue:\n\t- Once again looking for any extreme outliers that could possibly be inaccurate values. This was done by sorting the values and looking at the minimum and maximum values. In this case their weren't any extreme outliers, there were however several null/NaN values. After inspecting the data set as a whole - and just the rows with NaN's- the NaN values were determined to be missing at random, and not supposed to represent zero values. The options were to try some form of imputation for these rows, or to drop the rows containing the nulls. Roughly 7% of the rows were null, since this left roughly 14000 rows, and didn't disproportional effect any of the independent variable types this was determined to be appropriate (see Figure 1 for a change in the number of rows per sales method after droping the NaN rows). \n    \n- Years as Customer:\n\t- `pd['nb_sold'].value_counts.sort_index()` was used to see all the values in the row. In this case the data appeared to be clean. However, it is known that company was formed in 1984, which means customers cannot have been a customer before then. To correct this the following code was used:\n    \t `rows_to_drop = sales_drop_na[sales_drop_na['years_as_customer']>39].index\n\t \tsales_drop_na.drop(rows_to_drop, inplace =True)`\n\t- Note: 39 was used as the max value since 1984 + 39 =2023.  \n        \n- Number of Website Visits (nb_site_visits):\n\t- `pd['nb_site_visits'].value_counts.sort_index()` was used to sort through the values, additionally a histogram was used to view the number of visits. There were no abnormal values and the histogram followed a normal distribution.\n\n- State\n\t- The same filtering code: `pd['nb_site_visits'].value_counts.sort_index()`, was used and the data was logical. All 50 states were included and there were no unexpected values.","metadata":{},"cell_type":"markdown","id":"36241e79-2f81-44e1-920b-03908c44701c"},{"source":"## Exploratory Analysis:\n**Figure 1.** The first goal was to view the number of customers per sales method for our 3 sale methods : Call, Email, Call + Email. This was done for both the original data set, to show both the number of customers, and also to show that the number of customers lost when NaN's were droped is consistent by group.\n\n![image](image.png)\n\nIt's clear the Email was the most popular sale method with over double the volume of the Email + Call method, and roughly 1.5 times the volume of the Call method.\n\n\n**Figure 2.** Next a histogram was used to view the spread of our revenue values.\n\n\n![image-2](image-2.png)\n\nThe histogram shows a few different trends, there are several peaks in the 20 - 60 range, a grouping from 75-125, and then there are distinct bell curve like distributions around the 155, 185, 235 marks.\n\n**Figure 3.** A boxplot was used to show the spread of the revenue by the sale method.\n\n![image-3](image-3.png)\n\nThe boxplot shows the clear distinction in revenue per customer by sales method with call having a median at 49, Email 96, and Email and Call at 184.7.\n\n**Figure 4.** Box and bar plots were once again used to look at the revenue by week, and the volume of orders by week. The best way to view both of these variables at once however was determined to be the following line graph with a line for each sales method\n\n![image-4](image-4.png)\n\nThis figure reiterates the relationship between the sales method and revenue per customer, while also showing the increase in revenue by week.","metadata":{},"cell_type":"markdown","id":"5f47164a-a9ad-4847-9c6a-6b726a4ab7e4"},{"source":"## Review of Analysis and Advice Moving Forward\n\nBefore getting started its important to note the metric that appears to be the most critical to monitor is the revenue per order. This metric can be viewed across our sales methods, over time, and in general over any category we can create for our orders. The revenue per order across sale methods is 94, and is 48, 97, and 184 by group (in Call, Email, Email and Call order respectively). Ideally, we would be able to have data on not only the revenue per order, but also the time spent on that individual order, so that we could see the effectiveness in the use of time. This could be interesting data for the sales team to start to collect moving forward.\n\nThe data shows a clear distinction in the revenue per sale by method, with the Email and Call (E+C) being the most effective, followed by the just Email (E) method, and the Phone Call (C) method. Based on the data the first recomendation would be to drop the Phone Call only sales method as a sales method. The report indicates that this requires the most labor and time from the sales team, but it is producing by far the least revenue per customer of the methods.\n\nDescribing the difference between the E+C and the E methods is more difficult to analyze. While the E+C method has the higher revenue per customer, the E method has greater than twice the volume, and thus a signifcantly higher in total revenue. While its tempting to suggest using the E+C method for every customer its important to note that the E+C method takes an average of 10 minutes per customer which amounts to 2,500 hours of work if we were to do this for every customer. Without information about the sales team size, or wages, its hard to determine if this is worth it, or if its an unrealistic or inefficent goal.\n\nA possible strategy could be targeting specific customers with different methods. In this case we could keep track of average order size, and use the email by itself for lower spending customers, while customers who spend more on average would recieve the emails and the 10 minute phone call. This could be a more realistic goal for our sales team, and still takes advantage of the trend we have seen between sales methods and revenue.\n\nIts also interesting that the revenue per customer increases with time. Correlation analysis shows a strong positive linear relationship between week and number of products sold (r=0.81) , and Figure 4 shows this relationship exists for all of the sales methods. This might be interesting to pass along to the sales team, that they should not nessecraily be prioritizing early sales. Figure 4 also shows an increase of the slope of the line after week 3 when the second email was sent. It might be interesting for the marketing team to look at the effectiveness of this email, and the possiblity of increasing email frequency (this could have limiting returns).\n\nThe other variables do not seem to be obviosuly predictive towards our metric of interest. There aren't significant trends by state, and generally the states with the most orders are just the most populus states. Revenue per website visit increases linearally but there is only a week relationship (r=.32). It is interesting that years as a customer has a negative weak linear relationship with revenue, website visits, and number of items sold. This indicates that the 'long lasting relationships' the company values aren't actually producing value (according to this data). \n\nIn summary, the revenue per order for customers who just recieved the phone call was the lowest by far, and also required the most work. Its clear this method should be dropped as it is not a viable alternative. The email generated the most total revenue and required the least work, and its our reccomendation that this method should be used to target customers with history of lower volume orders. The Email and Call group was the most effective, and the sale team should increase the use of this method as much as their resources allow. It should definately be used for customers that are known to place larger orders. The data also shows average revenue increases with time, with the average revenue highest in week 6. This could indicate value in patience with our customers. ","metadata":{},"cell_type":"markdown","id":"8ee3e73a-27a5-45ce-9873-19f0052663b7"},{"source":"","metadata":{},"id":"c22f7f5b-2a69-4515-8b29-7b0e94829f11","cell_type":"markdown"},{"source":"## ✅ When you have finished...\n-  Publish your Workspace using the option on the left\n-  Check the published version of your report:\n\t-  Can you see everything you want us to grade?\n    -  Are all the graphics visible?\n-  Review the grading rubric. Have you included everything that will be graded?\n-  Head back to the [Certification Dashboard](https://app.datacamp.com/certification) to submit your practical exam report and record your presentation","metadata":{},"id":"9c5042af-7f73-4808-b735-c262418c9395","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}